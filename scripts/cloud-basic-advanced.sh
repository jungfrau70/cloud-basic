#!/bin/bash

# Cloud Basic Advanced Helper Script
# ê³ ë„í™”ëœ Cloud Basic ì‹¤ìŠµ ë„êµ¬

# ì˜¤ë¥˜ ì²˜ë¦¬ ì„¤ì •
set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ
set -u  # ì •ì˜ë˜ì§€ ì•Šì€ ë³€ìˆ˜ ì‚¬ìš© ì‹œ ì˜¤ë¥˜
set -o pipefail  # íŒŒì´í”„ë¼ì¸ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¢…ë£Œ

# ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ ì‹œ ì •ë¦¬ í•¨ìˆ˜
cleanup() {
    echo "ìŠ¤í¬ë¦½íŠ¸ê°€ ì¢…ë£Œë©ë‹ˆë‹¤. ì •ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤..."
    # í•„ìš”í•œ ì •ë¦¬ ì‘ì—… ì¶”ê°€
}

# ì‹ í˜¸ íŠ¸ë© ì„¤ì •
trap cleanup EXIT INT TERM

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Logging functions
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }
log_header() { echo -e "${PURPLE}[HEADER]${NC} $1"; }

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$(dirname "$SCRIPT_DIR")")"
AUTOMATION_DIR="$PROJECT_ROOT/repo/automation"
AUTOMATION_TESTS_DIR="$PROJECT_ROOT/repo/automation_tests"
LOG_FILE="$PROJECT_ROOT/cloud-basic-advanced.log"

# Initialize log file
init_log() {
    echo "=== Cloud Basic Advanced Helper Log ===" > "$LOG_FILE"
    echo "Started at: $(date)" >> "$LOG_FILE"
    echo "Script directory: $SCRIPT_DIR" >> "$LOG_FILE"
    echo "Project root: $PROJECT_ROOT" >> "$LOG_FILE"
    echo "" >> "$LOG_FILE"
}

# Log function
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" >> "$LOG_FILE"
    echo "$1"
}

# Environment check functions
check_aws_cli() {
    log_info "AWS CLI ìƒíƒœ í™•ì¸ ì¤‘..."
    if command -v aws &> /dev/null; then
        AWS_VERSION=$(aws --version 2>&1 | cut -d' ' -f1)
        log_success "AWS CLI ì„¤ì¹˜ë¨: $AWS_VERSION"
        
        # Check AWS credentials
        if aws sts get-caller-identity &> /dev/null; then
            AWS_ACCOUNT=$(aws sts get-caller-identity --query Account --output text 2>/dev/null)
            AWS_USER=$(aws sts get-caller-identity --query Arn --output text 2>/dev/null | cut -d'/' -f2)
            log_success "AWS ê³„ì • ì—°ê²°ë¨: $AWS_ACCOUNT ($AWS_USER)"
            return 0
        else
            log_error "AWS ê³„ì • ì„¤ì • í•„ìš”: aws configure ì‹¤í–‰"
            return 1
        fi
    else
        log_error "AWS CLI ì„¤ì¹˜ í•„ìš”"
        return 1
    fi
}

check_gcp_cli() {
    log_info "GCP CLI ìƒíƒœ í™•ì¸ ì¤‘..."
    if command -v gcloud &> /dev/null; then
        GCP_VERSION=$(gcloud version --format="value(Google Cloud SDK)" 2>/dev/null)
        log_success "GCP CLI ì„¤ì¹˜ë¨: $GCP_VERSION"
        
        # Check GCP authentication
        if gcloud auth list --filter=status:ACTIVE --format="value(account)" &> /dev/null; then
            GCP_ACCOUNT=$(gcloud auth list --filter=status:ACTIVE --format="value(account)" | head -1)
            GCP_PROJECT=$(gcloud config get-value project 2>/dev/null)
            log_success "GCP ê³„ì • ì—°ê²°ë¨: $GCP_ACCOUNT (í”„ë¡œì íŠ¸: $GCP_PROJECT)"
            return 0
        else
            log_error "GCP ê³„ì • ì„¤ì • í•„ìš”: gcloud auth login ì‹¤í–‰"
            return 1
        fi
    else
        log_error "GCP CLI ì„¤ì¹˜ í•„ìš”"
        return 1
    fi
}

check_python() {
    log_info "Python ìƒíƒœ í™•ì¸ ì¤‘..."
    if command -v python3 &> /dev/null; then
        PYTHON_VERSION=$(python3 --version 2>&1 | cut -d' ' -f2)
        log_success "Python3 ì„¤ì¹˜ë¨: $PYTHON_VERSION"
        return 0
    elif command -v python &> /dev/null; then
        PYTHON_VERSION=$(python --version 2>&1 | cut -d' ' -f2)
        log_success "Python ì„¤ì¹˜ë¨: $PYTHON_VERSION"
        return 0
    else
        log_error "Python ì„¤ì¹˜ í•„ìš”"
        return 1
    fi
}

# Comprehensive environment check
comprehensive_environment_check() {
    log_header "=== Cloud Basic í™˜ê²½ ì²´í¬ ì‹œì‘ ==="
    
    local checks_passed=0
    local total_checks=3
    
    check_aws_cli && ((checks_passed++))
    check_gcp_cli && ((checks_passed++))
    check_python && ((checks_passed++))
    
    log_header "=== í™˜ê²½ ì²´í¬ ê²°ê³¼ ==="
    log_info "í†µê³¼: $checks_passed/$total_checks"
    
    if [ $checks_passed -eq $total_checks ]; then
        log_success "ğŸ‰ ëª¨ë“  í™˜ê²½ ì²´í¬ í†µê³¼!"
        return 0
    else
        log_warning "âš ï¸ ì¼ë¶€ í™˜ê²½ ì²´í¬ ì‹¤íŒ¨. ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
        return 1
    fi
}

# Resource management functions
list_aws_resources() {
    log_header "=== AWS ë¦¬ì†ŒìŠ¤ í˜„í™© ==="
    
    if ! check_aws_cli; then
        return 1
    fi
    
    # EC2 instances
    log_info "EC2 ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì¤‘..."
    aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,State.Name,InstanceType,PublicIpAddress,Tags[?Key==`Name`].Value|[0]]' --output table 2>/dev/null || log_warning "EC2 ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"
    
    # S3 buckets
    log_info "S3 ë²„í‚· ì¡°íšŒ ì¤‘..."
    aws s3 ls 2>/dev/null || log_warning "S3 ë²„í‚· ì¡°íšŒ ì‹¤íŒ¨"
    
    # IAM users
    log_info "IAM ì‚¬ìš©ì ì¡°íšŒ ì¤‘..."
    aws iam list-users --query 'Users[*].[UserName,CreateDate]' --output table 2>/dev/null || log_warning "IAM ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨"
}

list_gcp_resources() {
    log_header "=== GCP ë¦¬ì†ŒìŠ¤ í˜„í™© ==="
    
    if ! check_gcp_cli; then
        return 1
    fi
    
    # Compute instances
    log_info "Compute ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì¤‘..."
    gcloud compute instances list --format="table(name,zone,status,machineType,externalIP)" 2>/dev/null || log_warning "Compute ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"
    
    # Cloud Storage buckets
    log_info "Cloud Storage ë²„í‚· ì¡°íšŒ ì¤‘..."
    gsutil ls 2>/dev/null || log_warning "Cloud Storage ë²„í‚· ì¡°íšŒ ì‹¤íŒ¨"
    
    # IAM service accounts
    log_info "IAM ì„œë¹„ìŠ¤ ê³„ì • ì¡°íšŒ ì¤‘..."
    gcloud iam service-accounts list --format="table(email,displayName)" 2>/dev/null || log_warning "IAM ì„œë¹„ìŠ¤ ê³„ì • ì¡°íšŒ ì‹¤íŒ¨"
}

# Cost analysis functions
analyze_aws_costs() {
    log_header "=== AWS ë¹„ìš© ë¶„ì„ ==="
    
    if ! check_aws_cli; then
        return 1
    fi
    
    log_info "AWS ë¹„ìš© ë¶„ì„ ì¤‘... (Cost Explorer API í•„ìš”)"
    
    # Check for unused resources
    log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì¤‘..."
    
    # Unused EBS volumes
    log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” EBS ë³¼ë¥¨:"
    aws ec2 describe-volumes --filters "Name=status,Values=available" --query 'Volumes[*].[VolumeId,Size,VolumeType,CreateTime]' --output table 2>/dev/null || log_warning "EBS ë³¼ë¥¨ ì¡°íšŒ ì‹¤íŒ¨"
    
    # Unused Elastic IPs
    log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” Elastic IP:"
    aws ec2 describe-addresses --query 'Addresses[?InstanceId==null].[PublicIp,AllocationId]' --output table 2>/dev/null || log_warning "Elastic IP ì¡°íšŒ ì‹¤íŒ¨"
    
    # Empty S3 buckets
    log_info "ë¹„ì–´ìˆëŠ” S3 ë²„í‚·:"
    aws s3 ls | while read -r bucket_info; do
        bucket_name=$(echo "$bucket_info" | awk '{print $3}')
        if [ -n "$bucket_name" ]; then
            object_count=$(aws s3 ls "s3://$bucket_name" --recursive --summarize 2>/dev/null | grep "Total Objects: 0" || echo "has objects")
            if [[ "$object_count" == *"Total Objects: 0"* ]]; then
                echo "  - $bucket_name (ë¹„ì–´ìˆìŒ)"
            fi
        fi
    done
}

analyze_gcp_costs() {
    log_header "=== GCP ë¹„ìš© ë¶„ì„ ==="
    
    if ! check_gcp_cli; then
        return 1
    fi
    
    log_info "GCP ë¹„ìš© ë¶„ì„ ì¤‘..."
    
    # Check for unused resources
    log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì¤‘..."
    
    # Unused persistent disks
    log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì˜êµ¬ ë””ìŠ¤í¬:"
    gcloud compute disks list --filter="status:READY AND -users:*" --format="table(name,zone,sizeGb,type)" 2>/dev/null || log_warning "ì˜êµ¬ ë””ìŠ¤í¬ ì¡°íšŒ ì‹¤íŒ¨"
    
    # Unused static IPs
    log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì •ì  IP:"
    gcloud compute addresses list --filter="status:RESERVED AND -users:*" --format="table(name,region,address)" 2>/dev/null || log_warning "ì •ì  IP ì¡°íšŒ ì‹¤íŒ¨"
    
    # Empty Cloud Storage buckets
    log_info "ë¹„ì–´ìˆëŠ” Cloud Storage ë²„í‚·:"
    gsutil ls 2>/dev/null | while read -r bucket_uri; do
        if [ -n "$bucket_uri" ]; then
            bucket_name=$(echo "$bucket_uri" | sed 's|gs://||' | sed 's|/||')
            object_count=$(gsutil ls -l "gs://$bucket_name" 2>/dev/null | wc -l)
            if [ "$object_count" -le 1 ]; then
                echo "  - $bucket_name (ë¹„ì–´ìˆìŒ)"
            fi
        fi
    done
}

# Practice automation functions
run_day1_practice() {
    log_header "=== Day 1 ì‹¤ìŠµ ì‹¤í–‰ ==="
    
    local day1_scripts=(
        "cloud_basics.sh"
        "iam_basics.sh"
        "vm_services.sh"
        "storage_services.sh"
    )
    
    for script in "${day1_scripts[@]}"; do
        local script_path="$AUTOMATION_DIR/day1/$script"
        
        if [ -f "$script_path" ]; then
            log_info "Day 1 ì‹¤ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: $script"
            chmod +x "$script_path"
            cd "$(dirname "$script_path")"
            ./"$script"
            
            if [ $? -eq 0 ]; then
                log_success "âœ… $script ì‹¤í–‰ ì™„ë£Œ"
            else
                log_error "âŒ $script ì‹¤í–‰ ì‹¤íŒ¨"
            fi
        else
            log_error "ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $script_path"
        fi
    done
}

run_day2_practice() {
    log_header "=== Day 2 ì‹¤ìŠµ ì‹¤í–‰ ==="
    
    local day2_scripts=(
        "networking_basics.sh"
        "security_basics.sh"
        "database_services.sh"
        "comprehensive_practice.sh"
    )
    
    for script in "${day2_scripts[@]}"; do
        local script_path="$AUTOMATION_DIR/day2/$script"
        
        if [ -f "$script_path" ]; then
            log_info "Day 2 ì‹¤ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: $script"
            chmod +x "$script_path"
            cd "$(dirname "$script_path")"
            ./"$script"
            
            if [ $? -eq 0 ]; then
                log_success "âœ… $script ì‹¤í–‰ ì™„ë£Œ"
            else
                log_error "âŒ $script ì‹¤í–‰ ì‹¤íŒ¨"
            fi
        else
            log_error "ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $script_path"
        fi
    done
}

# Automation test functions
run_automation_tests() {
    log_header "=== ìë™í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ==="
    
    if [ -d "$AUTOMATION_TESTS_DIR" ]; then
        log_info "ìë™í™” í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™: $AUTOMATION_TESTS_DIR"
        cd "$AUTOMATION_TESTS_DIR"
        
        # Run dry-run test
        if [ -f "dry_run_test.py" ]; then
            log_info "Dry-run í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
            python3 dry_run_test.py
        else
            log_error "dry_run_test.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            return 1
        fi
        
        # Run basic course tests
        if [ -f "run_basic_course_tests.py" ]; then
            log_info "Basic ê³¼ì • í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
            python3 run_basic_course_tests.py
        else
            log_error "run_basic_course_tests.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            return 1
        fi
    else
        log_error "ìë™í™” í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $AUTOMATION_TESTS_DIR"
        return 1
    fi
}

run_automation_generation() {
    log_header "=== ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ==="
    
    if [ -d "$AUTOMATION_TESTS_DIR" ]; then
        log_info "ìë™í™” í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™: $AUTOMATION_TESTS_DIR"
        cd "$AUTOMATION_TESTS_DIR"
        
        # Run automation generation
        if [ -f "basic_course_automation.py" ]; then
            log_info "ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘..."
            python3 basic_course_automation.py
        else
            log_error "basic_course_automation.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            return 1
        fi
    else
        log_error "ìë™í™” í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $AUTOMATION_TESTS_DIR"
        return 1
    fi
}

# Cleanup functions
cleanup_aws_resources() {
    log_header "=== AWS ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ==="
    
    if ! check_aws_cli; then
        return 1
    fi
    
    log_warning "AWS ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
    read -r response
    
    if [[ "$response" =~ ^[Yy]$ ]]; then
        log_info "AWS ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘..."
        
        # Terminate all running instances (except those with "keep" tag)
        log_info "ì‹¤í–‰ ì¤‘ì¸ EC2 ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ ì¤‘..."
        aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --query 'Reservations[*].Instances[?!Tags[?Key==`keep`]].[InstanceId]' --output text | xargs -r aws ec2 terminate-instances --instance-ids 2>/dev/null || log_warning "EC2 ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ ì‹¤íŒ¨"
        
        # Delete unused EBS volumes
        log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” EBS ë³¼ë¥¨ ì‚­ì œ ì¤‘..."
        aws ec2 describe-volumes --filters "Name=status,Values=available" --query 'Volumes[*].VolumeId' --output text | xargs -r aws ec2 delete-volume --volume-ids 2>/dev/null || log_warning "EBS ë³¼ë¥¨ ì‚­ì œ ì‹¤íŒ¨"
        
        # Delete empty S3 buckets
        log_info "ë¹„ì–´ìˆëŠ” S3 ë²„í‚· ì‚­ì œ ì¤‘..."
        aws s3 ls | while read -r bucket_info; do
            bucket_name=$(echo "$bucket_info" | awk '{print $3}')
            if [ -n "$bucket_name" ]; then
                object_count=$(aws s3 ls "s3://$bucket_name" --recursive --summarize 2>/dev/null | grep "Total Objects: 0" || echo "has objects")
                if [[ "$object_count" == *"Total Objects: 0"* ]]; then
                    log_info "ë¹„ì–´ìˆëŠ” ë²„í‚· ì‚­ì œ: $bucket_name"
                    aws s3 rb "s3://$bucket_name" 2>/dev/null || log_warning "ë²„í‚· $bucket_name ì‚­ì œ ì‹¤íŒ¨"
                fi
            fi
        done
        
        log_success "AWS ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ"
    else
        log_info "AWS ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì·¨ì†Œë¨"
    fi
}

cleanup_gcp_resources() {
    log_header "=== GCP ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ==="
    
    if ! check_gcp_cli; then
        return 1
    fi
    
    log_warning "GCP ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
    read -r response
    
    if [[ "$response" =~ ^[Yy]$ ]]; then
        log_info "GCP ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘..."
        
        # Delete all instances (except those with "keep" label)
        log_info "Compute ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ì¤‘..."
        gcloud compute instances list --filter="NOT labels.keep:*" --format="value(name,zone)" | while read -r name zone; do
            if [ -n "$name" ] && [ -n "$zone" ]; then
                gcloud compute instances delete "$name" --zone="$zone" --quiet 2>/dev/null || log_warning "ì¸ìŠ¤í„´ìŠ¤ $name ì‚­ì œ ì‹¤íŒ¨"
            fi
        done
        
        # Delete unused persistent disks
        log_info "ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì˜êµ¬ ë””ìŠ¤í¬ ì‚­ì œ ì¤‘..."
        gcloud compute disks list --filter="status:READY AND -users:*" --format="value(name,zone)" | while read -r name zone; do
            if [ -n "$name" ] && [ -n "$zone" ]; then
                gcloud compute disks delete "$name" --zone="$zone" --quiet 2>/dev/null || log_warning "ë””ìŠ¤í¬ $name ì‚­ì œ ì‹¤íŒ¨"
            fi
        done
        
        # Delete empty Cloud Storage buckets
        log_info "ë¹„ì–´ìˆëŠ” Cloud Storage ë²„í‚· ì‚­ì œ ì¤‘..."
        gsutil ls 2>/dev/null | while read -r bucket_uri; do
            if [ -n "$bucket_uri" ]; then
                bucket_name=$(echo "$bucket_uri" | sed 's|gs://||' | sed 's|/||')
                object_count=$(gsutil ls -l "gs://$bucket_name" 2>/dev/null | wc -l)
                if [ "$object_count" -le 1 ]; then
                    log_info "ë¹„ì–´ìˆëŠ” ë²„í‚· ì‚­ì œ: $bucket_name"
                    gsutil rm -r "gs://$bucket_name" 2>/dev/null || log_warning "ë²„í‚· $bucket_name ì‚­ì œ ì‹¤íŒ¨"
                fi
            fi
        done
        
        log_success "GCP ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ"
    else
        log_info "GCP ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì·¨ì†Œë¨"
    fi
}

# Main menu
main_menu() {
    while true; do
        clear
        log_header "=== Cloud Basic Advanced Helper ==="
        echo -e "${CYAN}í˜„ì¬ ì‹œê°„: $(date)${NC}"
        echo -e "${CYAN}ë¡œê·¸ íŒŒì¼: $LOG_FILE${NC}"
        echo ""
        echo "1. ğŸ” ì¢…í•© í™˜ê²½ ì²´í¬"
        echo "2. ğŸ“Š AWS ë¦¬ì†ŒìŠ¤ í˜„í™©"
        echo "3. ğŸ“Š GCP ë¦¬ì†ŒìŠ¤ í˜„í™©"
        echo "4. ğŸ’° AWS ë¹„ìš© ë¶„ì„"
        echo "5. ğŸ’° GCP ë¹„ìš© ë¶„ì„"
        echo "6. ğŸš€ Day 1 ì‹¤ìŠµ ì‹¤í–‰ (ì „ì²´)"
        echo "7. ğŸš€ Day 2 ì‹¤ìŠµ ì‹¤í–‰ (ì „ì²´)"
        echo "8. ğŸ§ª ìë™í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
        echo "9. ğŸ”§ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"
        echo "10. ğŸ§¹ AWS ë¦¬ì†ŒìŠ¤ ì •ë¦¬"
        echo "11. ğŸ§¹ GCP ë¦¬ì†ŒìŠ¤ ì •ë¦¬"
        echo "12. ğŸ“‹ ë¡œê·¸ ë³´ê¸°"
        echo "0. ì¢…ë£Œ"
        echo ""
        read -p "ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš” (0-12): " choice
        
        case $choice in
            1) comprehensive_environment_check ;;
            2) list_aws_resources ;;
            3) list_gcp_resources ;;
            4) analyze_aws_costs ;;
            5) analyze_gcp_costs ;;
            6) run_day1_practice ;;
            7) run_day2_practice ;;
            8) run_automation_tests ;;
            9) run_automation_generation ;;
            10) cleanup_aws_resources ;;
            11) cleanup_gcp_resources ;;
            12) 
                log_info "ë¡œê·¸ íŒŒì¼ ë‚´ìš©:"
                cat "$LOG_FILE" | tail -50
                ;;
            0) 
                log_info "Cloud Basic Advanced Helperë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."
                exit 0
                ;;
            *) 
                log_error "ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
                ;;
        esac
        
        echo ""
        read -p "ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”..."
    done
}

# Initialize and start
init_log
log_header "Cloud Basic Advanced Helper ì‹œì‘"
main_menu
