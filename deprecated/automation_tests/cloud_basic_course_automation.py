#!/usr/bin/env python3
"""
Cloud Basic ê³¼ì • ìë™í™” ìŠ¤í¬ë¦½íŠ¸ (ê°±ì‹  - ë©±ë“±ì„± ì¶”ê°€)
AWS/GCP ê¸°ì´ˆ ì‹¤ìŠµ ìë™í™”

- êµì¬ ì—°ê³„ì„±:
  - Cloud Basic 1ì¼ì°¨: AWS & GCP ê¸°ì´ˆ ì„œë¹„ìŠ¤ ì‹¤ìŠµ
  - Cloud Basic 2ì¼ì°¨: ë„¤íŠ¸ì›Œí¬, ë³´ì•ˆ ë° ë°ì´í„°ë² ì´ìŠ¤ ì‹¤ìŠµ
- ì£¼ìš” ê¸°ëŠ¥:
  - ê° ê³¼ì •ì˜ ì‹¤ìŠµ ë¦¬ì†ŒìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ìƒì„± ë° ì‚­ì œí•©ë‹ˆë‹¤.
  - ë¦¬ì†ŒìŠ¤ ìƒì„± ì „ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì—¬, ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰ ì‹œ ì‹¤íŒ¨ ì§€ì ë¶€í„° ì´ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë©±ë“±ì„±)
"""

import os
import sys
import json
import time
import logging
from pathlib import Path
from typing import Dict, Any
import boto3
from botocore.exceptions import ClientError
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('basic_course_automation.log', mode='w'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BasicCourseAutomation:
    """Cloud Basic ê³¼ì • ìë™í™” í´ë˜ìŠ¤ (ë©±ë“±ì„± ì ìš©)"""
    
    def __init__(self, base_path: Path):
        self.base_path = base_path
        self.course_name = "cloud_basic"
        self.status = "not_started"
        self.created_resources = {"aws": [], "gcp": []}
        self.config = self.load_config()
        self.aws_iam_client = boto3.client('iam', region_name=self.config['aws_region'])
        self.aws_ec2_client = boto3.client('ec2', region_name=self.config['aws_region'])
        self.aws_s3_client = boto3.client('s3', region_name=self.config['aws_region'])

    def load_config(self) -> Dict[str, Any]:
        return {
            "aws_region": "ap-northeast-2",
            "gcp_project_id": os.getenv("GCP_PROJECT_ID", "your-gcp-project-id"),
            "gcp_region": "asia-northeast3",
            "gcp_zone": "asia-northeast3-a",
            "project_prefix": "mcp-basic-course",
            "aws_ami_id": "ami-0c9c94243ce534a55"
        }

    def day1_aws_basics(self) -> bool:
        logger.info("ğŸŒ… 1ì¼ì°¨: AWS ê¸°ì´ˆ ì‹¤ìŠµ ì‹œì‘")
        prefix = self.config['project_prefix']
        user_name = f"{prefix}-user"
        sg_name = f"{prefix}-sg"
        instance_name = f"{prefix}-instance"
        bucket_name = f"{prefix}-bucket-{self.config['aws_region']}"

        try:
            # 1. IAM ì‚¬ìš©ì í™•ì¸ ë° ìƒì„±
            try:
                self.aws_iam_client.get_user(UserName=user_name)
                logger.info(f"IAM User {user_name} already exists. Skipping creation.")
            except ClientError as e:
                if e.response['Error']['Code'] == 'NoSuchEntity':
                    self.aws_iam_client.create_user(UserName=user_name)
                    logger.info(f"âœ… IAM User ìƒì„± ì™„ë£Œ: {user_name}")
                else:
                    raise
            self.created_resources["aws"].append({"type": "iam_user", "name": user_name})

            # 2. ë³´ì•ˆ ê·¸ë£¹ í™•ì¸ ë° ìƒì„±
            try:
                sg_response = self.aws_ec2_client.describe_security_groups(GroupNames=[sg_name])
                sg_id = sg_response['SecurityGroups'][0]['GroupId']
                logger.info(f"Security Group {sg_name} already exists. Skipping creation.")
            except ClientError as e:
                if e.response['Error']['Code'] == 'InvalidGroup.NotFound':
                    sg = self.aws_ec2_client.create_security_group(GroupName=sg_name, Description='Allow SSH, HTTP, HTTPS')
                    sg_id = sg['GroupId']
                    self.aws_ec2_client.authorize_security_group_ingress(
                        GroupId=sg_id,
                        IpPermissions=[
                            {'IpProtocol': 'tcp', 'FromPort': 22, 'ToPort': 22, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]},
                            {'IpProtocol': 'tcp', 'FromPort': 80, 'ToPort': 80, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]},
                            {'IpProtocol': 'tcp', 'FromPort': 443, 'ToPort': 443, 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]}
                        ]
                    )
                    logger.info(f"âœ… Security Group ìƒì„± ì™„ë£Œ: {sg_id}")
                else:
                    raise
            self.created_resources["aws"].append({"type": "security_group", "id": sg_id, "name": sg_name})

            # 3. EC2 ì¸ìŠ¤í„´ìŠ¤ í™•ì¸ ë° ìƒì„±
            # ... (Implementation for checking existing instance)
            logger.info("EC2 instance creation logic to be implemented with idempotency.")

            # 4. S3 ë²„í‚· í™•ì¸ ë° ìƒì„±
            try:
                self.aws_s3_client.head_bucket(Bucket=bucket_name)
                logger.info(f"S3 Bucket {bucket_name} already exists. Skipping creation.")
            except ClientError as e:
                if e.response['Error']['Code'] == '404':
                    self.aws_s3_client.create_bucket(
                        Bucket=bucket_name,
                        CreateBucketConfiguration={'LocationConstraint': self.config['aws_region']}
                    )
                    logger.info(f"âœ… S3 Bucket ìƒì„± ì™„ë£Œ: {bucket_name}")
                else:
                    raise
            self.created_resources["aws"].append({"type": "s3_bucket", "name": bucket_name})

            logger.info("âœ… 1ì¼ì°¨ AWS ê¸°ì´ˆ ì‹¤ìŠµ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ 1ì¼ì°¨ AWS ê¸°ì´ˆ ì‹¤ìŠµ ì‹¤íŒ¨: {e}", exc_info=True)
            return False

    def day2_gcp_basics(self) -> bool:
        logger.info("ğŸŒ… 2ì¼ì°¨: GCP ê¸°ì´ˆ ì‹¤ìŠµ ì‹œì‘")
        # ... (Idempotency logic for GCP to be added here)
        logger.info("GCP automation logic to be implemented with idempotency.")
        return True

    def cleanup_resources(self):
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘")
        for resource in reversed(self.created_resources["aws"]):
            try:
                if resource["type"] == "security_group":
                    time.sleep(10) # Allow instances to terminate
                    self.aws_ec2_client.delete_security_group(GroupId=resource.get("id"), GroupName=resource.get("name"))
                elif resource["type"] == "iam_user":
                    self.aws_iam_client.delete_user(UserName=resource["name"])
                elif resource["type"] == "s3_bucket":
                    self.aws_s3_client.delete_bucket(Bucket=resource["name"])
                logger.info(f"Deleted AWS resource: {resource}")
            except ClientError as e:
                logger.error(f"Failed to delete AWS resource {resource}: {e}")

    def run_course(self):
        logger.info(f"ğŸš€ {self.course_name} ê³¼ì • ì‹œì‘")
        self.status = "in_progress"
        if not self.day1_aws_basics():
            logger.error("âŒ 1ì¼ì°¨ ì‹¤ìŠµ ì‹¤íŒ¨")
        # ... (Run day2)
        self.status = "completed"
        logger.info(f"ğŸ‰ {self.course_name} ê³¼ì • ì™„ë£Œ!")
        self.cleanup_resources()

if __name__ == "__main__":
    automation = BasicCourseAutomation(Path(__file__).parent)
    automation.run_course()